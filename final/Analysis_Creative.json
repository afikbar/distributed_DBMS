{"paragraphs":[{"title":"Cool trick to increase  elasticsearch max search size","text":"%sh\ncurl -XPUT 'localhost:9200/sandiego_male_viol/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/modesto_arrested/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/modesto_gender/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/leftovers/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/sandiego_viol/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/reddings/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/buttonwillow_male_viol/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/redding_male_viol/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/sandiego_arrested/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/buttonwillow_loc/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"\ncurl -XPUT 'localhost:9200/modesto_male_viol/_settings' -d ' { \"index\" : { \"max_result_window\" : \"900000\" } }' -H \"Content-Type: application/json\"","user":"anonymous","dateUpdated":"2018-06-27T13:19:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh","tableHide":true,"editorHide":true,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  62740 --:--:-- --:--:-- --:--:-- 62740\r  0    21    0    21    0    49    632   1474 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  71324 --:--:-- --:--:-- --:--:-- 71324\r  0    21    0    21    0    49    482   1126 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  70200 --:--:-- --:--:-- --:--:-- 70200\r  0    21    0    21    0    49    665   1552 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  71742 --:--:-- --:--:-- --:--:-- 71742\r  0    21    0    21    0    49    768   1793 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  49049 --:--:-- --:--:-- --:--:-- 49049\r  0    21    0    21    0    49    644   1502 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  67586 --:--:-- --:--:-- --:--:-- 67586\r  0    21    0    21    0    49    606   1414 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  69111 --:--:-- --:--:-- --:--:-- 69111\r  0    21    0    21    0    49    457   1068 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  69209 --:--:-- --:--:-- --:--:-- 69209\r  0    21    0    21    0    49    842   1966 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  70707 --:--:-- --:--:-- --:--:-- 70707{\"acknowledged\":true}\r  0    21    0    21    0    49    744   1737 --:--:-- --:--:-- --:--:--     0\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  67867 --:--:-- --:--:-- --:--:-- 67867\r  0    21    0    21    0    49    925   2158 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0    49      0  71324 --:--:-- --:--:-- --:--:-- 71324\r  0    21    0    21    0    49    715   1668 --:--:-- --:--:-- --:--:--     0\n{\"acknowledged\":true}"}]},"apps":[],"jobName":"paragraph_1530001592976_-2053512580","id":"20180626-082632_472081460","dateCreated":"2018-06-26T08:26:32+0000","dateStarted":"2018-06-27T13:19:32+0000","dateFinished":"2018-06-27T13:19:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10162"},{"title":"Definitions...","text":"%pyspark\n\nfrom elasticsearch import Elasticsearch\nfrom pyspark.sql import Row\n\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql.functions import date_format\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.mllib.stat import Statistics\n\n\n# creates a dictionary of index name : index DataFrame\n# note: creates it for all indices in elasticsearch instance.\ndef create_indices_dict(es):  # returns array of indices\n    array = {}\n    for index in es.indices.get_alias(\"*\").keys():\n        index = str(index)\n        res = es.search(index=index, size=90000)\n        items = map(lambda item: {k: v for k, v in item['_source'].items() + [('_id', int(item['_id']))]},\n                    res['hits']['hits'])\n        rows = map(lambda item: Row(**item), items)\n        array[index] = sqlContext.createDataFrame(rows)\n    return array\n\n\n# uses the indices dictionary to build the original dataset\n# assuming distribution that we used in H.W 1.\ndef get_combined_df(indices_dict):  # input is dict of {indexName:indexDF}\n    viol_array = {k: v for k, v in indices_dict.items() if\n                  k in ['buttonwillow_male_viol', 'modesto_male_viol', 'redding_male_viol', 'sandiego_male_viol']}\n    viol_union = indices_dict['sandiego_viol']\n    for index, df in viol_array.items():\n        viol_union = viol_union.union(df)\n\n    arstd_union = indices_dict['modesto_arrested'].union(indices_dict['sandiego_arrested'])\n    unioned_joined = viol_union.join(arstd_union, ['_id'])\n\n    loc_joined = unioned_joined.join(indices_dict['buttonwillow_loc'], ['_id'])\n    gender_joined = loc_joined.join(indices_dict['modesto_gender'], ['_id'])\n    left_joined = gender_joined.join(indices_dict['leftovers'], ['_id'])\n\n    left_joined = left_joined.select(\n        ['_id', 'id', 'stop_date', 'location_raw', 'driver_gender', 'driver_race', 'violation', 'search_conducted',\n         'is_arrested'])\n    indices_dict['reddings'] = indices_dict['reddings'].select(\n        ['_id', 'id', 'stop_date', 'location_raw', 'driver_gender', 'driver_race', 'violation', 'search_conducted',\n         'is_arrested'])\n\n    combined_data = left_joined.union(indices_dict['reddings'])\n    return combined_data\n\n\n# input is combined data, creates from it features and labels for classifications.\n# returns df with features,labels cols.\ndef create_features_labels(combined_data):\n    combined_data = combined_data.withColumn('date', (combined_data.stop_date).cast(\"date\"))\n    combined_data = combined_data.withColumn('week_end', (date_format(combined_data.date, 'u') > 4).cast('integer'))\n\n    indexer = StringIndexer(inputCol=\"location_raw\", outputCol=\"location_raw_index\")\n    combined_data = indexer.fit(combined_data).transform(combined_data)\n\n    indexer = StringIndexer(inputCol=\"driver_gender\", outputCol=\"driver_gender_index\")\n    combined_data = indexer.fit(combined_data).transform(combined_data)\n\n    indexer = StringIndexer(inputCol=\"driver_race\", outputCol=\"driver_race_index\")\n    combined_data = indexer.fit(combined_data).transform(combined_data)\n\n    indexer = StringIndexer(inputCol=\"violation\", outputCol=\"violation_index\")\n    combined_data = indexer.fit(combined_data).transform(combined_data)\n\n    combined_data = combined_data.withColumn('search_conducted_binary',\n                                             (combined_data.search_conducted).cast('integer'))\n    combined_data = combined_data.withColumn('label', (combined_data.is_arrested).cast('integer'))\n\n    assembler = VectorAssembler(\n        inputCols=[\"location_raw_index\", \"driver_gender_index\", \"driver_race_index\", \"violation_index\",\n                   \"search_conducted_binary\", \"week_end\"], outputCol=\"features\")\n    combined_data = assembler.transform(combined_data)\n\n    to_learn_data = combined_data.select(\"features\", \"label\")\n    return to_learn_data\n\n\n# creates predictions for structed df (features, labels) using RandomForest model.\n# returns a dataframe with the predictions.\ndef get_predictions_df(data, tree_num=10):\n    # Index labels, adding metadata to the label column.\n    # Fit on whole dataset to include all labels in index.\n    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n\n    # Automatically identify categorical features, and index them.\n    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(data)\n\n    # Split the data into training and test sets (30% held out for testing)\n    (trainingData, testData) = data.randomSplit([0.8, 0.2])\n\n    # Train a RandomForest model.\n    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=tree_num)\n\n    # Convert indexed labels back to original labels.\n    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n\n    # Chain indexers and forest in a Pipeline\n    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n\n    # Train model.  This also runs the indexers.\n    model = pipeline.fit(trainingData)\n\n    # Make predictions.\n    predictions = model.transform(testData)\n    return predictions\n\n\n# evaluates our predictions using standard measurements(percision, accuracy, recall & F1)\n# returns the measurements.\ndef evaluation(prd_df):\n    prd_df = prd_df.withColumn('TP', ((prd_df.label == 1) & (prd_df.predictedLabel == 1)).cast('integer'))\n    prd_df = prd_df.withColumn('TN', ((prd_df.label == 0) & (prd_df.predictedLabel == 0)).cast('integer'))\n    prd_df = prd_df.withColumn('FN', ((prd_df.label == 1) & (prd_df.predictedLabel == 0)).cast('integer'))\n    prd_df = prd_df.withColumn('FP', ((prd_df.label == 0) & (prd_df.predictedLabel == 1)).cast('integer'))\n    tp = sum(x.TP for x in prd_df.select('TP').collect())\n    tn = sum(x.TN for x in prd_df.select('TN').collect())\n    fn = sum(x.FN for x in prd_df.select('FN').collect())\n    fp = sum(x.FP for x in prd_df.select('FP').collect())\n    accuracy = float(tp + tn) / (tp + tn + fp + fn)\n    percision = float(tp) / (tp + fp)\n    recall = float(tp) / (tp + fn)\n    f1measure = 2 * (recall * percision) / (recall + percision)\n    return {\"Accuracy\": accuracy, \"Percision\": percision, \"Recall\": recall, \"F1 Score\": f1measure}\n","user":"anonymous","dateUpdated":"2018-06-27T13:19:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1529964242215_1741440442","id":"20180625-220402_808151472","dateCreated":"2018-06-25T22:04:02+0000","dateStarted":"2018-06-27T13:19:32+0000","dateFinished":"2018-06-27T13:19:32+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:10163"},{"title":"Get combined DataFrame","text":"%pyspark\n\nes = Elasticsearch()\n\nindex_dict = create_indices_dict(es)\n\ndata = get_combined_df(index_dict)","user":"anonymous","dateUpdated":"2018-06-27T13:19:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1530019972056_2019149246","id":"20180626-133252_784881156","dateCreated":"2018-06-26T13:32:52+0000","dateStarted":"2018-06-27T13:19:33+0000","dateFinished":"2018-06-27T13:19:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10164"},{"title":"Do some science (: (break, predict, evaluate)","text":"%pyspark\n\nto_learn_data = create_features_labels(data)\n\npredictions = get_predictions_df(to_learn_data, tree_num=30) # 30 trees is da best\n\nperformance_measures = evaluation(predictions)\n\nfor measure,result in performance_measures.items():\n    print \"{} is: {}\".format(measure,result)\n\n","user":"anonymous","dateUpdated":"2018-06-27T13:19:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Recall is: 0.740875912409\nPercision is: 0.697594501718\nF1 Score is: 0.718584070796\nAccuracy is: 0.985486079416\n"}]},"apps":[],"jobName":"paragraph_1529964592511_-555234657","id":"20180625-220952_1441384196","dateCreated":"2018-06-25T22:09:52+0000","dateStarted":"2018-06-27T13:19:34+0000","dateFinished":"2018-06-27T13:22:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10165"},{"title":"Gain the stats","text":"%pyspark\ntotal_by_city = data\\\n                    .groupBy(\"location_raw\")\\\n                    .count()\\\n                    .selectExpr(\"location_raw as City\",\"count as Total_Count\")\ntotal_by_city.show()                    \nlist_city = map(lambda row: row.asDict(), total_by_city.collect())\ndict_city = {str(row['City']):row['Total_Count'] for row in list_city}\n","user":"anonymous","dateUpdated":"2018-06-27T13:19:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+-----------+\n|        City|Total_Count|\n+------------+-----------+\n|   San Diego|      31672|\n|     Redding|       5804|\n|Buttonwillow|       7407|\n|     Modesto|       9970|\n+------------+-----------+\n\n"}]},"apps":[],"jobName":"paragraph_1530017584158_1165792631","id":"20180626-125304_273296002","dateCreated":"2018-06-26T12:53:04+0000","dateStarted":"2018-06-27T13:19:49+0000","dateFinished":"2018-06-27T13:22:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10166"},{"title":"Gender in Cities","text":"%pyspark\n\ngender_by_city = {city:\n                        data\\\n                        .where(\"location_raw = '{}'\".format(city))\\\n                        .groupBy(\"driver_gender\")\\\n                        .count()\\\n                        .selectExpr(\"driver_gender as {}_by_Gender\".format(city.replace(\" \", \"_\")),\"count as Count\")\\\n                        # .withColumn(\"Precentage\", (data.count/dict_city[city]))\\\n                        # .drop(\"Count\")\n                        \n                        \n                        for city in dict_city.keys()\n}\n\n\nfor city,df in gender_by_city.items():\n    df.withColumn(\"Precentage\", (df.Count*100/dict_city[city])).drop(\"Count\").show()","user":"anonymous","dateUpdated":"2018-06-27T13:19:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+------------------+\n|Redding_by_Gender|        Precentage|\n+-----------------+------------------+\n|                F|32.891109579600275|\n|                M| 67.10889042039972|\n+-----------------+------------------+\n\n+-------------------+------------------+\n|San_Diego_by_Gender|        Precentage|\n+-------------------+------------------+\n|                  F|30.244379893912605|\n|                  M| 69.75562010608739|\n+-------------------+------------------+\n\n+-----------------+-----------------+\n|Modesto_by_Gender|       Precentage|\n+-----------------+-----------------+\n|                F|33.04914744232698|\n|                M|66.95085255767302|\n+-----------------+-----------------+\n\n+----------------------+------------------+\n|Buttonwillow_by_Gender|        Precentage|\n+----------------------+------------------+\n|                     F|28.608073444039423|\n|                     M| 71.39192655596058|\n+----------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1530014570997_-588297495","id":"20180626-120250_638669102","dateCreated":"2018-06-26T12:02:50+0000","dateStarted":"2018-06-27T13:22:39+0000","dateFinished":"2018-06-27T13:23:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10167"},{"title":"Race in Cities","text":"%pyspark\n\nrace_by_city = {city:\n                    data\\\n                    .where(\"location_raw = '{}'\".format(city))\\\n                    .groupBy(\"driver_race\")\\\n                    .count()\\\n                    .selectExpr(\"driver_race as {}_by_Race\".format(city.replace(\" \", \"_\")),\"count as Count\")\\\n                    for city in ['San Diego', 'Redding', 'Buttonwillow', 'Modesto']\n}\n\nfor city,df in gender_by_city.items():\n    df.withColumn(\"Precentage\", (df.Count*100/dict_city[city])).drop(\"Count\").show()","user":"anonymous","dateUpdated":"2018-06-27T13:19:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+------------------+\n|Redding_by_Gender|        Precentage|\n+-----------------+------------------+\n|                F|32.891109579600275|\n|                M| 67.10889042039972|\n+-----------------+------------------+\n\n+-------------------+------------------+\n|San_Diego_by_Gender|        Precentage|\n+-------------------+------------------+\n|                  F|30.244379893912605|\n|                  M| 69.75562010608739|\n+-------------------+------------------+\n\n+-----------------+-----------------+\n|Modesto_by_Gender|       Precentage|\n+-----------------+-----------------+\n|                F|33.04914744232698|\n|                M|66.95085255767302|\n+-----------------+-----------------+\n\n+----------------------+------------------+\n|Buttonwillow_by_Gender|        Precentage|\n+----------------------+------------------+\n|                     F|28.608073444039423|\n|                     M| 71.39192655596058|\n+----------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1530016395692_789587593","id":"20180626-123315_162591744","dateCreated":"2018-06-26T12:33:15+0000","dateStarted":"2018-06-27T13:22:57+0000","dateFinished":"2018-06-27T13:24:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10168"},{"title":"Correlation between Violation & is_arrested","text":"%pyspark\r\n\r\n# Check correlation between violation type and is_arrested, can be splitted by gender.\r\n# gender input must be 'F' or 'M'\r\ndef violation_correl(data, gender=None):\r\n    if gender:\r\n        print \"Correlation between Violation type & is_arrested in {}:\".format('Females' if gender == 'F' else 'Males')\r\n        cor_data = data.filter(data.driver_gender == gender)\r\n    else:\r\n        print \"Correlation between Violation type & is_arrested:\"\r\n        cor_data = data\r\n    cor_data = cor_data.withColumn('binary_arrest', (cor_data.is_arrested).cast('integer'))\r\n    cor_data = cor_data.withColumn('binary_EQ', (cor_data.violation == 'Equipment').cast('integer'))\r\n    cor_data = cor_data.withColumn('binary_DUI', (cor_data.violation == 'DUI').cast('integer'))\r\n    cor_data = cor_data.withColumn('binary_Other', (cor_data.violation == 'Other').cast('integer'))\r\n    cor_data = cor_data.withColumn('binary_MV', (cor_data.violation == 'Moving violation').cast('integer'))\r\n\r\n    arrest = [x.binary_arrest for x in cor_data.select('binary_arrest').collect()]\r\n    seriesA = sc.parallelize(arrest)\r\n    EQ = [x.binary_EQ for x in cor_data.select('binary_EQ').collect()]\r\n    DUI = [x.binary_DUI for x in cor_data.select('binary_DUI').collect()]\r\n    Other = [x.binary_Other for x in cor_data.select('binary_Other').collect()]\r\n    MV = [x.binary_MV for x in cor_data.select('binary_MV').collect()]\r\n\r\n    viols = {'Equipment violation': EQ,\r\n             'DUI violation': DUI,\r\n             'Other violation': Other,\r\n             'Moving violation': MV\r\n             }\r\n    \r\n    for viol, lis in viols.items():\r\n        tempSeries = sc.parallelize(lis)\r\n        viol_correl = Statistics.corr(seriesA, tempSeries, method=\"pearson\")\r\n        print \"The Correlation between {} to being arrested is: {}\".format(viol, viol_correl)\r\n","user":"anonymous","dateUpdated":"2018-06-27T13:19:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1530020597554_1669899057","id":"20180626-134317_199490811","dateCreated":"2018-06-26T13:43:17+0000","dateStarted":"2018-06-27T13:23:30+0000","dateFinished":"2018-06-27T13:24:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10169"},{"text":"%pyspark\nviolation_correl(data)","user":"anonymous","dateUpdated":"2018-06-27T13:19:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Correlation between Violation type & is_arrested:\nThe Correlation between Other violation to being arrested is: 0.00964852157602\nThe Correlation between Equipment violation to being arrested is: -0.0332392488017\nThe Correlation between Moving violation to being arrested is: -0.0404046463745\nThe Correlation between DUI violation to being arrested is: 0.168996962718\n"}]},"apps":[],"jobName":"paragraph_1530020770838_1912319868","id":"20180626-134610_1624609889","dateCreated":"2018-06-26T13:46:10+0000","dateStarted":"2018-06-27T13:24:03+0000","dateFinished":"2018-06-27T13:24:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10170"},{"title":"Correlation between Violation & is_arrested within Female population","text":"%pyspark\nviolation_correl(data, gender='F')","user":"anonymous","dateUpdated":"2018-06-27T13:19:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Correlation between Violation type & is_arrested in Females:\nThe Correlation between Other violation to being arrested is: 0.0140246733692\nThe Correlation between Equipment violation to being arrested is: -0.0399104216519\nThe Correlation between Moving violation to being arrested is: -0.0296982447751\nThe Correlation between DUI violation to being arrested is: 0.147097362529\n"}]},"apps":[],"jobName":"paragraph_1530021698601_1358219034","id":"20180626-140138_921092893","dateCreated":"2018-06-26T14:01:38+0000","dateStarted":"2018-06-27T13:24:04+0000","dateFinished":"2018-06-27T13:24:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10171"},{"title":"Correlation between Race & is_arrested","text":"%pyspark\n# Check correlation between race  and is_arrested.\ndef race_correl(data):\n    cor_data = data.withColumn('binary_arrest', (data.is_arrested).cast('integer'))\n    arrest = [x.binary_arrest for x in cor_data.select('binary_arrest').collect()]\n    seriesA = sc.parallelize(arrest)\n    races = set([str(x[0]) for x in data.select('driver_race').collect()])\n    for race in races:\n        cor_data = cor_data.withColumn(race, (cor_data.driver_race == race).cast('integer'))\n\n    racedict = {'White': [x.White for x in cor_data.select('White').collect()],\n                'Asian': [x.Asian for x in cor_data.select('Asian').collect()],\n                'Black': [x.Black for x in cor_data.select('Black').collect()],\n                'Other': [x.Other for x in cor_data.select('Other').collect()],\n                'Hispanic': [x.Hispanic for x in cor_data.select('Hispanic').collect()]}\n    \n    print \"Correlation between Race & is_arrested:\"\n    for race, lis in racedict.items():\n        tempSeries = sc.parallelize(lis)\n        race_correl = Statistics.corr(seriesA, tempSeries, method=\"pearson\")\n        print \"The correlation between being {} to being arrested is: {}\".format(race, race_correl)","user":"anonymous","dateUpdated":"2018-06-27T13:19:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1530004773538_-529047735","id":"20180626-091933_1519325098","dateCreated":"2018-06-26T09:19:33+0000","dateStarted":"2018-06-27T13:24:32+0000","dateFinished":"2018-06-27T13:24:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10172"},{"text":"%pyspark\nrace_correl(data)","user":"anonymous","dateUpdated":"2018-06-27T13:19:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Correlation between Race & is_arrested:\nThe correlation between being Hispanic to being arrested is: 0.018378350435\nThe correlation between being White to being arrested is: -0.00288293884784\nThe correlation between being Other to being arrested is: -0.0191171689887\nThe correlation between being Black to being arrested is: 0.00724767880865\nThe correlation between being Asian to being arrested is: -0.0176226646221\n"}]},"apps":[],"jobName":"paragraph_1530019528841_-572161956","id":"20180626-132528_1061504974","dateCreated":"2018-06-26T13:25:28+0000","dateStarted":"2018-06-27T13:24:58+0000","dateFinished":"2018-06-27T13:25:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10173"},{"title":"The end (:","text":"%sh\nsudo service elasticsearch stop\n","user":"anonymous","dateUpdated":"2018-06-27T16:35:17+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"env: /etc/init.d/elasticsearch: Permission denied\n"},{"type":"TEXT","data":"ExitValue: 126"}]},"apps":[],"jobName":"paragraph_1530019539389_1449708839","id":"20180626-132539_658268344","dateCreated":"2018-06-26T13:25:39+0000","dateStarted":"2018-06-27T13:19:36+0000","dateFinished":"2018-06-27T13:19:37+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:10174"},{"text":"%sh\n","user":"anonymous","dateUpdated":"2018-06-27T13:19:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1530105576245_513150493","id":"20180627-131936_181617300","dateCreated":"2018-06-27T13:19:36+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:10175"}],"name":"final_organized","id":"2DJ6KNNCD","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}